{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T00:45:51.569326Z","iopub.execute_input":"2023-09-15T00:45:51.569721Z","iopub.status.idle":"2023-09-15T00:45:51.971582Z","shell.execute_reply.started":"2023-09-15T00:45:51.569684Z","shell.execute_reply":"2023-09-15T00:45:51.970431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.imports import *\nnp.set_printoptions(linewidth=100)\n\nimport pandas as pd\ndf = pd.read_csv('/kaggle/input/dsaa-6100-titanic-dicision_tree/train.csv')\ntst_df = pd.read_csv('/kaggle/input/dsaa-6100-titanic-dicision_tree/test.csv')\nmodes = df.mode().iloc[0] #每列众数（出现频率最高的数）\n#发现有多个众数\n#import random\n#modes = df.mode().iloc[0]  # 获取所有列的众数\n# 处理多个众数的情况\n#modes_list = [tuple(row) for row in modes.values]  # 将多个众数保存为元组的列表\n#selected_modes = random.choice(modes_list)  # 随机选择一个众数组合\n#df.fillna(selected_modes, inplace=True)  # 填充数据\n\ndf.isna().sum()#查看缺失数据 isna（）返回布尔类型，缺失是True。.sum()求和，True=1,Faulse=0,总共多少缺失\n\ndf","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:51.973771Z","iopub.execute_input":"2023-09-15T00:45:51.974476Z","iopub.status.idle":"2023-09-15T00:45:52.584286Z","shell.execute_reply.started":"2023-09-15T00:45:51.974427Z","shell.execute_reply":"2023-09-15T00:45:52.583144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#预处理，对缺失值填充\ndef proc_data(df): # Define a function to process the data\n    df['Fare'] = df.Fare.fillna(0) # 为啥？下一步不就覆盖了嘛\n    df.fillna(modes, inplace=True) # 用modes中众数填充\n#新建一个LogFare，是Fare+1后再log，防止为0的情况，这样可以缩小数据范围，对于较大数据使得数据更具正态特征及降低对建模的影响\n    df['LogFare'] = np.log1p(df['Fare']) \n    df['Embarked'] = pd.Categorical(df.Embarked) #转换为分类数据类型，下面进行编码\n    df['Sex'] = pd.Categorical(df.Sex)#分类，二分类，将字符串变成0 1 便于后续建模\nproc_data(df) \nproc_data(tst_df) \ndf","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:52.585649Z","iopub.execute_input":"2023-09-15T00:45:52.586677Z","iopub.status.idle":"2023-09-15T00:45:52.636050Z","shell.execute_reply.started":"2023-09-15T00:45:52.586643Z","shell.execute_reply":"2023-09-15T00:45:52.634857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#浅浅分个类\ncats=[\"Sex\",\"Embarked\"]#分类特征，上面pd.Categorical(df.Embarked)转化为分类数据类型\nconts=['Age', 'SibSp', 'Parch', 'LogFare',\"Pclass\"]#连续特征\ndep=\"Survived\" #目标变量","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:52.639138Z","iopub.execute_input":"2023-09-15T00:45:52.639620Z","iopub.status.idle":"2023-09-15T00:45:52.645237Z","shell.execute_reply.started":"2023-09-15T00:45:52.639565Z","shell.execute_reply":"2023-09-15T00:45:52.643832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df.Sex.head() #查看 DataFrame 或 Series 的前5行","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:52.646456Z","iopub.execute_input":"2023-09-15T00:45:52.647246Z","iopub.status.idle":"2023-09-15T00:45:52.658075Z","shell.execute_reply.started":"2023-09-15T00:45:52.647212Z","shell.execute_reply":"2023-09-15T00:45:52.656673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nfig,axs = plt.subplots(1,2, figsize=(11,5))#fig 是一个代表整个图表的对象 axs是子图对象\nsns.barplot(data=df, y=dep, x=\"Sex\", ax=axs[0]).set(title=\"Survival rate\")#条形图axs[0]第一个子图\nsns.countplot(data=df, x=\"Sex\", ax=axs[1]).set(title=\"Histogram\");#计数图","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:52.659517Z","iopub.execute_input":"2023-09-15T00:45:52.659832Z","iopub.status.idle":"2023-09-15T00:45:54.619180Z","shell.execute_reply.started":"2023-09-15T00:45:52.659805Z","shell.execute_reply":"2023-09-15T00:45:54.618031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import random\nfrom sklearn.model_selection import train_test_split\n\nrandom.seed(6100) #每次运行代码时都会生成相同的随机数\ntrn_df,val_df = train_test_split(df, test_size=0.25)#分割成 train 和val验证集\ntrn_df[cats] = trn_df[cats].apply(lambda x: x.cat.codes)# 分类变量（categorical variables）进行编码\nval_df[cats] = val_df[cats].apply(lambda x: x.cat.codes)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:54.620628Z","iopub.execute_input":"2023-09-15T00:45:54.621571Z","iopub.status.idle":"2023-09-15T00:45:54.907413Z","shell.execute_reply.started":"2023-09-15T00:45:54.621519Z","shell.execute_reply":"2023-09-15T00:45:54.906331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def xs_y(df):\n    xs = df[cats+conts].copy()\n    return xs,df[dep] if dep in df else None #条件语句\n\ntrn_xs,trn_y = xs_y(trn_df)\nval_xs,val_y = xs_y(val_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:54.908577Z","iopub.execute_input":"2023-09-15T00:45:54.908847Z","iopub.status.idle":"2023-09-15T00:45:54.920793Z","shell.execute_reply.started":"2023-09-15T00:45:54.908823Z","shell.execute_reply":"2023-09-15T00:45:54.916972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = val_xs.Sex==0 # True =1\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(val_y, preds)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:54.922360Z","iopub.execute_input":"2023-09-15T00:45:54.922797Z","iopub.status.idle":"2023-09-15T00:45:54.937517Z","shell.execute_reply.started":"2023-09-15T00:45:54.922755Z","shell.execute_reply":"2023-09-15T00:45:54.936492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_fare = trn_df[trn_df.LogFare>0]\nfig,axs = plt.subplots(1,2, figsize=(11,5))\nsns.boxenplot(data=df_fare, x=dep, y=\"LogFare\", ax=axs[0]) #箱线图\nsns.kdeplot(data=df_fare, x=\"LogFare\", ax=axs[1]); #核密度估计图（kdeplot）","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:54.941721Z","iopub.execute_input":"2023-09-15T00:45:54.942066Z","iopub.status.idle":"2023-09-15T00:45:55.460897Z","shell.execute_reply.started":"2023-09-15T00:45:54.942036Z","shell.execute_reply":"2023-09-15T00:45:55.459990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = val_xs.LogFare>2.6 #只是简单二分，使得preds=1与存活映射\nmean_absolute_error(val_y, preds)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.462227Z","iopub.execute_input":"2023-09-15T00:45:55.462863Z","iopub.status.idle":"2023-09-15T00:45:55.473112Z","shell.execute_reply.started":"2023-09-15T00:45:55.462822Z","shell.execute_reply":"2023-09-15T00:45:55.471931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#子集得分，更全面地评估分割是否有利于减少目标变量值的不一致性。 数值越低，表示越纯，数值是inpurioty\ndef _side_score(side, y):\n    tot = side.sum() #布尔类型，也就是属于子集side的标准差*属于子集的样本数量\n    if tot <= 1:\n        return 0 #不足够提供信息\n    return y[side].std() * tot  #y中满足side的元素的标准差*tot个数 \n    #标准差体现目标y中分散程度即不一致性\n    #如果子集内部数据相近，标准差就小，分类就越纯 tot是为了考虑子集的大小对纯度的影响","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.474781Z","iopub.execute_input":"2023-09-15T00:45:55.477234Z","iopub.status.idle":"2023-09-15T00:45:55.482588Z","shell.execute_reply.started":"2023-09-15T00:45:55.477192Z","shell.execute_reply":"2023-09-15T00:45:55.481824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(col, y, split):\n     lhs = col <= split #小于等于split threshold在左侧分类，left_hands是一个布尔类型，\n        #他的sum（）是左侧的样本数量 ~lhs是右侧的，Y是目标样本，len(y)总样本长度\n     return (_side_score(lhs, y) + _side_score(~lhs, y)) / len(y)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.483902Z","iopub.execute_input":"2023-09-15T00:45:55.484548Z","iopub.status.idle":"2023-09-15T00:45:55.497668Z","shell.execute_reply.started":"2023-09-15T00:45:55.484509Z","shell.execute_reply":"2023-09-15T00:45:55.496774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score(trn_xs[\"Sex\"], trn_y, 0.5)\nscore(trn_xs[\"LogFare\"], trn_y, 2.6)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.499063Z","iopub.execute_input":"2023-09-15T00:45:55.499705Z","iopub.status.idle":"2023-09-15T00:45:55.514814Z","shell.execute_reply.started":"2023-09-15T00:45:55.499664Z","shell.execute_reply":"2023-09-15T00:45:55.513559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iscore(nm, split):# 特征名，分割点  这个交互只能在kaggle\n    col = trn_xs[nm]\n    return score(col, trn_y, split)#\n\nfrom ipywidgets import interact\ninteract(nm=conts, split=15.5)(iscore);#交互，允许用户通过滑块选择特征和分割点","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.517633Z","iopub.execute_input":"2023-09-15T00:45:55.518323Z","iopub.status.idle":"2023-09-15T00:45:55.554725Z","shell.execute_reply.started":"2023-09-15T00:45:55.518278Z","shell.execute_reply":"2023-09-15T00:45:55.553640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interact(nm=cats, split=2)(iscore);","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.556098Z","iopub.execute_input":"2023-09-15T00:45:55.557066Z","iopub.status.idle":"2023-09-15T00:45:55.588729Z","shell.execute_reply.started":"2023-09-15T00:45:55.557021Z","shell.execute_reply":"2023-09-15T00:45:55.587650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#以年龄为例，automatically找出年龄的最佳二分的threshold\nnm = \"Age\"\ncol = trn_xs[nm]\nunq = col.unique()#对col中值提取唯一值\nunq.sort()#按升序排列\nunq","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.590116Z","iopub.execute_input":"2023-09-15T00:45:55.591106Z","iopub.status.idle":"2023-09-15T00:45:55.601087Z","shell.execute_reply.started":"2023-09-15T00:45:55.591063Z","shell.execute_reply":"2023-09-15T00:45:55.599994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#计算在给定特征列（col）上进行二元分割的最佳分割点\nscores = np.array([score(col, trn_y, o) for o in unq if not np.isnan(o)])\n#列表推导式 if o in unq is not nan 就计算在o处分割的分数\nunq[scores.argmin()]#argmin() 函数找到了 scores 数组中最小值的索引\n#scores.argmin（）只返回第一个最小值，对于多个最小值，可以用np.where(scores == scores.min())[0][0]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.602454Z","iopub.execute_input":"2023-09-15T00:45:55.603483Z","iopub.status.idle":"2023-09-15T00:45:55.683247Z","shell.execute_reply.started":"2023-09-15T00:45:55.603441Z","shell.execute_reply":"2023-09-15T00:45:55.682001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#鉴于上面想法，定义一个函数\n# Define a function that finds the best binary split for a given column.\ndef min_col(df, nm):\n    # Extract the desired column and the dependent variable from the dataframe.\n    col, y = df[nm], df[dep]\n\n    # Get unique non-null values from the column. dropna（）就求掉了nan的值\n    unq = col.dropna().unique()\n\n    # Calculate the score for each unique value, skipping NaN values.\n    scores = np.array([score(col, y, o) for o in unq if not np.isnan(o)])\n\n    # Find the index of the best (minimum) score.\n    idx = scores.argmin()\n\n    # Return the unique value associated with the best score and the best score itself.\n    return unq[idx], scores[idx]\n    #返回最佳的cutoff点的数据以及最佳点作为cutoff的得分\n# Test the function on the \"Age\" column of the training dataframe.\nmin_col(trn_df, \"Age\")","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.684805Z","iopub.execute_input":"2023-09-15T00:45:55.685219Z","iopub.status.idle":"2023-09-15T00:45:55.770175Z","shell.execute_reply.started":"2023-09-15T00:45:55.685182Z","shell.execute_reply":"2023-09-15T00:45:55.769128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = cats+conts#分类型和连续型 cols 是一个包含列名的列表\n{o:min_col(trn_df, o) for o in cols}#使用字典推导来创建一个字典\n#键是 cols 列表中的列名 o，值是通过 min_col(trn_df, o) 函数计算得到的threshold和该分割值下对应的得分","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:45:55.771564Z","iopub.execute_input":"2023-09-15T00:45:55.772019Z","iopub.status.idle":"2023-09-15T00:45:56.039197Z","shell.execute_reply.started":"2023-09-15T00:45:55.771979Z","shell.execute_reply":"2023-09-15T00:45:56.038311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#使用布尔列表来筛选DataFrame，进行时，会返回一个true对应的新的dataframe\n#原本是每个特征都直接找最佳分割点，现在是对某个特征分割后，再找对应的其他特征分界点\n#先分男 女 男女之下再各自分\ncols.remove(\"Sex\")\nismale = trn_df.Sex==1 #=1 男\nmales,females = trn_df[ismale],trn_df[~ismale]\n{o:min_col(males, o) for o in cols}","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:50:18.585893Z","iopub.execute_input":"2023-09-15T00:50:18.586460Z","iopub.status.idle":"2023-09-15T00:50:18.820980Z","shell.execute_reply.started":"2023-09-15T00:50:18.586412Z","shell.execute_reply":"2023-09-15T00:50:18.819762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{o:min_col(females, o) for o in cols}","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:50:29.844689Z","iopub.execute_input":"2023-09-15T00:50:29.845080Z","iopub.status.idle":"2023-09-15T00:50:30.018375Z","shell.execute_reply.started":"2023-09-15T00:50:29.845050Z","shell.execute_reply":"2023-09-15T00:50:30.017041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"发现对于男，下一个最好的二分方法是age,对于女，下一个更好的分界是Pclass。所以，之前做的工作1、确定在这几个特征中，首先按哪个分（更纯净），其次各自找最佳的split方法","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\n#创建决策树分类器的类、导出决策树的可视化函数\nm = DecisionTreeClassifier(max_leaf_nodes=4).fit(trn_xs, trn_y);\n#m=决策树分类器对象,最大叶子节点的数量为 4，\n#将训练数据 trn_xs（特征）和 trn_y（目标变量，通常是标签）传递给 m 对象\nimport graphviz\n#export_graphviz包含在graphviz之中\n#（决策树模型，dataframe用于提供特征名，尺寸默认10，宽高比默认0.6，节点中数值的小数精度默认2，允许传递额外的关键字参数给 export_graphviz 函数）\ndef draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n    #使用 export_graphviz 函数生成决策树的可视化描述字符串（DOT 格式）\n    #（决策树模型，输出文件默认none，表示不写出；特征名；节点是否填色；节点是否显示圆角矩形；\n    #允许使用特殊字符；是否旋转；数值的小数精度；允许传递额外的参数）\n    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n                      special_characters=True, rotate=False, precision=precision, **kwargs)\n    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))\n    #graphviz.Source（）创建可视化的图形对象，接受DOT格式的文本字符串s（描述图形的结构和外观）作为参数\n    #re.sub('tree{',f'tree{{size={size}')是后面一个替换前面一个替换\n    #f'  '是Python的f-string，用于将 size 和 ratio 的值嵌入到字符串中","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:58:31.749213Z","iopub.execute_input":"2023-09-15T00:58:31.749615Z","iopub.status.idle":"2023-09-15T00:58:32.044411Z","shell.execute_reply.started":"2023-09-15T00:58:31.749583Z","shell.execute_reply":"2023-09-15T00:58:32.043403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_tree(m, trn_xs, size=10)\n#samples是这个节点样本一共多少，而value是实际死亡、存活的数量","metadata":{"execution":{"iopub.status.busy":"2023-09-15T00:59:35.884257Z","iopub.execute_input":"2023-09-15T00:59:35.884642Z","iopub.status.idle":"2023-09-15T00:59:36.105166Z","shell.execute_reply.started":"2023-09-15T00:59:35.884611Z","shell.execute_reply":"2023-09-15T00:59:36.104165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#gini的定义\ndef gini(cond):\n    \"\"\"\n    Compute the Gini impurity for a specified condition.\n\n    Parameters:\n    - cond: A boolean condition for filtering the dataframe.\n\n    Returns:\n    - The Gini impurity value for the filtered data.\n    \"\"\"\n\n    # Use the given condition to filter the dataframe and select the dependent variable column\n    act = df.loc[cond, dep]\n\n    # Calculate the Gini impurity:\n    # Gini impurity is calculated as 1 minus the sum of the squared probabilities of each class.\n    # In a binary classification (e.g., 0 and 1), if 'act.mean()' gives the probability of class '1',\n    # then '1 - act.mean()' gives the probability of class '0'.\n    # The formula then becomes: 1 - probability(1)^2 - probability(0)^2\n    return 1 - act.mean()**2 - (1-act).mean()**2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m = DecisionTreeClassifier(min_samples_leaf=50)\nm.fit(trn_xs, trn_y)\ndraw_tree(m, trn_xs, size=10)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:34:53.800328Z","iopub.execute_input":"2023-09-15T01:34:53.800730Z","iopub.status.idle":"2023-09-15T01:34:53.840385Z","shell.execute_reply.started":"2023-09-15T01:34:53.800698Z","shell.execute_reply":"2023-09-15T01:34:53.839572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_absolute_error(val_y, m.predict(val_xs))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:34:56.693100Z","iopub.execute_input":"2023-09-15T01:34:56.693452Z","iopub.status.idle":"2023-09-15T01:34:56.703203Z","shell.execute_reply.started":"2023-09-15T01:34:56.693426Z","shell.execute_reply":"2023-09-15T01:34:56.702117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tst_df[cats] = tst_df[cats].apply(lambda x: x.cat.codes) #分类数据编码为数字\ntst_xs,_ = xs_y(tst_df)#占位符_表示不需要目标变量\n\ndef subm(preds, suff):  #preds是模型的预测结果，suff是文件名的后缀\n    tst_df['Survived'] = preds  #将预测结果preds添加到测试数据集的新列Survived中\n    sub_df = tst_df[['PassengerId','Survived']]  #从测试数据集中选择两列\n    sub_df.to_csv(f'submission.csv', index=False)  #保存为CSV文件，文件名为submission.csv\n    #index=False表示不保存行索引\nsubm(m.predict(tst_xs), 'tree') #'tree'是一个后缀，用于构建输出文件名。\n#训练好的模型m对测试集进行测试","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:35:38.304226Z","iopub.execute_input":"2023-09-15T01:35:38.304639Z","iopub.status.idle":"2023-09-15T01:35:38.322620Z","shell.execute_reply.started":"2023-09-15T01:35:38.304607Z","shell.execute_reply":"2023-09-15T01:35:38.321410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the average of lots of uncorrelated random errors is zero.\n# train each of them on a different random subset of the data\n#随机森林\ndef get_tree(prop=0.85):\n    \"\"\"\n    Generate and fit a decision tree classifier using a subset of the data.\n\n    Parameters:\n    - prop (float, optional): Proportion of the data to use for training. Default is 0.85.\n\n    Returns:\n    - A trained DecisionTreeClassifier.\n    \"\"\"\n\n    # Determine the number of data points in the training set\n    n = len(trn_y)\n\n    # Randomly select a subset of indices based on the specified proportion\n    idxs = random.choice(n, int(n*prop))\n\n    # Train a DecisionTreeClassifier on the selected subset and return it\n    return DecisionTreeClassifier(min_samples_leaf=5).fit(trn_xs.iloc[idxs], trn_y.iloc[idxs])","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:49:45.226533Z","iopub.execute_input":"2023-09-15T01:49:45.226916Z","iopub.status.idle":"2023-09-15T01:49:45.233952Z","shell.execute_reply.started":"2023-09-15T01:49:45.226887Z","shell.execute_reply":"2023-09-15T01:49:45.232561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trees = [get_tree() for t in range(100)]","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:49:49.514893Z","iopub.execute_input":"2023-09-15T01:49:49.515369Z","iopub.status.idle":"2023-09-15T01:49:49.867899Z","shell.execute_reply.started":"2023-09-15T01:49:49.515314Z","shell.execute_reply":"2023-09-15T01:49:49.866849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_probs = [t.predict(val_xs) for t in trees]\navg_probs = np.stack(all_probs).mean(0)\n\nmean_absolute_error(val_y, avg_probs)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:50:59.976802Z","iopub.execute_input":"2023-09-15T01:50:59.977831Z","iopub.status.idle":"2023-09-15T01:51:00.126199Z","shell.execute_reply.started":"2023-09-15T01:50:59.977780Z","shell.execute_reply":"2023-09-15T01:51:00.124973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(99, min_samples_leaf=5)\nrf.fit(trn_xs, trn_y);\nmean_absolute_error(val_y, rf.predict(val_xs))","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:53:34.673686Z","iopub.execute_input":"2023-09-15T01:53:34.674097Z","iopub.status.idle":"2023-09-15T01:53:34.875958Z","shell.execute_reply.started":"2023-09-15T01:53:34.674063Z","shell.execute_reply":"2023-09-15T01:53:34.875130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm(rf.predict(tst_xs), 'rf')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:54:06.698681Z","iopub.execute_input":"2023-09-15T01:54:06.699076Z","iopub.status.idle":"2023-09-15T01:54:06.720669Z","shell.execute_reply.started":"2023-09-15T01:54:06.699045Z","shell.execute_reply":"2023-09-15T01:54:06.719464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(dict(cols=trn_xs.columns, imp=m.feature_importances_)).plot('cols', 'imp', 'barh');","metadata":{"execution":{"iopub.status.busy":"2023-09-15T01:56:24.457282Z","iopub.execute_input":"2023-09-15T01:56:24.457695Z","iopub.status.idle":"2023-09-15T01:56:24.765174Z","shell.execute_reply.started":"2023-09-15T01:56:24.457652Z","shell.execute_reply":"2023-09-15T01:56:24.763901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}